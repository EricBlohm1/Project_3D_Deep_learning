{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55580231",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6081a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "url = \"https://3dshapenets.cs.princeton.edu/ModelNet10.zip\"\n",
    "zip_path = \"ModelNet10.zip\"\n",
    "dataset_folder = \"ModelNet10\"\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    # Remove the zip file to save space\n",
    "    os.remove(zip_path)\n",
    "\n",
    "    #Created when extracting. Not useful to windows users.\n",
    "    if os.path.exists(\"__MACOSX\"):\n",
    "        shutil.rmtree(\"__MACOSX\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c4c665",
   "metadata": {},
   "source": [
    "## For windows users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_directory = os.path.join(os.getcwd(), \"ModelNet10\")\n",
    "\n",
    "# Walk through the directory and remove .DS_Store files\n",
    "for root, dirs, files in os.walk(dataset_directory):\n",
    "    for file in files:\n",
    "        if file == '.DS_Store':\n",
    "            os.remove(os.path.join(root, file))\n",
    "\n",
    "print(\"Removed all .DS_Store files from the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694cecf",
   "metadata": {},
   "source": [
    "## Precompute voxelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b34c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pads to have consistent size. \n",
    "# Centers to make training better, network dont have to learn positions, only shape.\n",
    "def voxelize(mesh, res):\n",
    "    pitch = mesh.bounding_box.extents.max() / res\n",
    "    voxel_grid = mesh.voxelized(pitch=pitch)\n",
    "    voxel_matrix = voxel_grid.matrix.astype(np.float32)\n",
    "\n",
    "    padded = np.zeros((res, res, res), dtype=np.float32)\n",
    "    shape = voxel_matrix.shape\n",
    "    min_dim = np.minimum(shape, (res, res, res))\n",
    "\n",
    "    # Find which index the object should start, if the object is (30,30,30), and res = 32, \n",
    "    # the object should start at 1 (1 padding to the left and 1 to the right).\n",
    "    start = [(res - min_dim[i]) // 2 for i in range(3)]\n",
    "    end = [start[i] + min_dim[i] for i in range(3)]\n",
    "    padded[start[0]:end[0], start[1]:end[1], start[2]:end[2]] = voxel_matrix[:min_dim[0], :min_dim[1], :min_dim[2]]\n",
    "\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1dac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"../ModelNet10\"\n",
    "output_directory = \"./ModelNet10_voxelized_64\"\n",
    "res = 32\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    for object_folder in os.listdir(dataset_directory):\n",
    "        if object_folder == \"README.txt\":\n",
    "            continue\n",
    "\n",
    "        object_folder_path = os.path.join(dataset_directory, object_folder)\n",
    "\n",
    "        for split in ['train', 'test']:\n",
    "            split_path = os.path.join(object_folder_path, split)\n",
    "\n",
    "            save_split_path = os.path.join(output_directory, object_folder, split)\n",
    "            os.makedirs(save_split_path, exist_ok=True)\n",
    "\n",
    "            for file in os.listdir(split_path):\n",
    "                if file.endswith('.off'):\n",
    "                    file_path = os.path.join(split_path,file)\n",
    "\n",
    "                    mesh = trimesh.load_mesh(file_path)\n",
    "                    voxels = voxelize(mesh, res)\n",
    "\n",
    "                    save_path = os.path.join(save_split_path, file.replace('.off','.npy'))\n",
    "                    np.save(save_path, voxels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
